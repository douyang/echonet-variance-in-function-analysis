{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ishan/Documents/Stanford/echonet-function-evaluation/Deep Learning/echonet/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# David Ouyang \n",
    "# Ishan Jain \n",
    "# 9/25/2020\n",
    "# Training loop to choose ESV/EDV frame count\n",
    "\n",
    "import statistics\n",
    "import echonet\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import math \n",
    "import skimage.segmentation\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import PIL.Image\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "print(echonet.__file__)\n",
    "\n",
    "#outputpath = \"C:\\\\Users\\\\Remote\\\\Documents\\\\ishanjain\\\\echonet-function-evaluation\\\\Deep Learning\\\\output\\\\video\\\\r2plus1d_18_32_1_pretrained\"\n",
    "outputpath = \"/Users/ishan/Documents/Stanford/EchoData/output/video/r2plus1d_18_32_1_pretrained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.774605 33.955395 34.318237] [51.00695 51.19394 51.51023]\n",
      "1276\n"
     ]
    }
   ],
   "source": [
    "#Test \n",
    "\n",
    "mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(split=\"test\"))\n",
    "print(mean,std)\n",
    "\n",
    "modelname=\"r2plus1d_18\"\n",
    "frames=32\n",
    "period=1\n",
    "tasks=\"NormalizedLargeIndex\"#\"NormalizedSmallIndex\"\n",
    "pretrained=True\n",
    "\n",
    "kwargs = {\"target_type\": tasks,\n",
    "          \"mean\": mean,\n",
    "          \"std\": std,\n",
    "          \"length\": frames,\n",
    "          \"period\": period\n",
    "          }\n",
    "\n",
    "    # Set up datasets and dataloaders\n",
    "test_dataset = echonet.datasets.Echo(split=\"test\", **kwargs)\n",
    "\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWork = 5\n",
    "batch_size=8\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "dataloaders = {'test':test_dataloader}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Set up model\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "# for phase in dataloaders.keys():\n",
    "#     with torch.set_grad_enabled(phase == \"train\"):\n",
    "#         with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "#             for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "#                 print(i, x.shape, outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is not available, cpu weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/159 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x1413dfa50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/159 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aa8ea2fc63bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m                         \u001b[0;31m#print(x, outcome)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0moutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[\"out\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                         \u001b[0;31m#output.write(#Filename, Prediction, GroundTruth, Difference betwen the two)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "#this is for large index\n",
    "\n",
    "num_epochs = 1\n",
    "verbose = True\n",
    "\n",
    "startingEpoch = 0\n",
    "startingBestLoss = 100000\n",
    "priorCheckpoint = os.path.join(outputpath, \"verbose_normalizedlargeindex_best.pt\") # you need to load different weights\n",
    "\n",
    "toGPU = torch.cuda.is_available()\n",
    "#toGPU = False\n",
    "\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "if toGPU:\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "if os.path.exists(priorCheckpoint):   \n",
    "    if toGPU:\n",
    "        print(\"Loading Weights\")\n",
    "        checkpoint = torch.load(priorCheckpoint)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        model.eval()\n",
    "        \n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "    else:\n",
    "        print(\"cuda is not available, cpu weights\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        checkpoint = torch.load(priorCheckpoint, map_location = \"cpu\")\n",
    "        state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict_cpu)\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "        \n",
    "logFilename = os.path.join(outputpath, \"test_normalizedlargeindex.csv\")\n",
    "\n",
    "totaldiff = 0\n",
    "differences = []\n",
    "\n",
    "with open(logFilename, 'w') as output:\n",
    "    for epoch in range(1, 2):\n",
    "        for phase in dataloaders.keys():\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                    print(enumerate(dataloaders[phase]))\n",
    "                    for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "                        \n",
    "                        #print(x, outcome)\n",
    "                        x = x.to(device)\n",
    "                        outcome = outcome.to(device)\n",
    "                        p = model(x)#[\"out\"]\n",
    "                        #output.write(#Filename, Prediction, GroundTruth, Difference betwen the two)\n",
    "                        \n",
    "                        for i in range(batch_size):\n",
    "                            output.write(str(i) + \",\" + str(round(p[i].item())) + \",\" + str(outcome[i].item()) + \",\" + str( abs(round(p[i].item()) - outcome[i].item())) + \"\\n\")\n",
    "                            #print(str(round(p[i].item())) + \",\" + str(outcome[i].item()) + \",\" + str( abs(round(p[i].item()) - outcome[i].item())))\n",
    "                            totaldiff += abs(round(p[i].item()) - outcome[i].item())\n",
    "                            differences.append(abs(round(p[i].item()) - outcome[i].item()))\n",
    "                        #loss = torch.nn.functional.mse_loss(p.view(-1), outcome)\n",
    "\n",
    "                        progressbar.set_postfix_str(phase +\"{:.1f} {:.4f}\".format(epoch, i))\n",
    "                        progressbar.update()\n",
    "                        \n",
    "                        print(\"This is the average difference:\", totaldiff / 1276)\n",
    "print(statistics.pstdev(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "Loading Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                 | 2/159 [00:13<24:59,  9.55s/it, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.0603448275862069\n",
      "This is the average difference: 0.10266457680250783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▋                                                                | 4/159 [00:14<12:18,  4.76s/it, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.14655172413793102\n",
      "This is the average difference: 0.1896551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▍                                                               | 6/159 [00:14<06:08,  2.41s/it, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.24921630094043887\n",
      "This is the average difference: 0.2993730407523511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▎                                                              | 8/159 [00:14<03:11,  1.27s/it, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.3487460815047022\n",
      "This is the average difference: 0.40752351097178685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████                                                             | 10/159 [00:15<01:44,  1.42it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.4670846394984326\n",
      "This is the average difference: 0.5109717868338558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████▉                                                            | 12/159 [00:15<01:02,  2.35it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.5572100313479624\n",
      "This is the average difference: 0.5979623824451411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████▋                                                           | 14/159 [00:15<00:41,  3.50it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.6426332288401254\n",
      "This is the average difference: 0.6959247648902821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▌                                                          | 16/159 [00:15<00:31,  4.56it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.7413793103448276\n",
      "This is the average difference: 0.7797805642633229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████▎                                                         | 18/159 [00:16<00:25,  5.56it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.8393416927899686\n",
      "This is the average difference: 0.8879310344827587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████▏                                                        | 20/159 [00:16<00:23,  5.81it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 0.9263322884012539\n",
      "This is the average difference: 0.9858934169278997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████▉                                                        | 22/159 [00:16<00:22,  6.11it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.0493730407523512\n",
      "This is the average difference: 1.097962382445141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████▊                                                       | 24/159 [00:17<00:21,  6.23it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.1598746081504703\n",
      "This is the average difference: 1.2272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████▋                                                      | 26/159 [00:17<00:20,  6.41it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.2609717868338557\n",
      "This is the average difference: 1.3087774294670846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████▍                                                     | 28/159 [00:17<00:19,  6.59it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.3463949843260188\n",
      "This is the average difference: 1.4059561128526645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████▎                                                    | 30/159 [00:18<00:19,  6.49it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.452194357366771\n",
      "This is the average difference: 1.4976489028213167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████                                                    | 32/159 [00:18<00:19,  6.42it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.5603448275862069\n",
      "This is the average difference: 1.6300940438871474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████▉                                                   | 34/159 [00:18<00:19,  6.56it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.665360501567398\n",
      "This is the average difference: 1.6959247648902822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████▋                                                  | 36/159 [00:19<00:19,  6.39it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.7366771159874608\n",
      "This is the average difference: 1.793103448275862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████▌                                                 | 38/159 [00:19<00:19,  6.33it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.8573667711598747\n",
      "This is the average difference: 1.9130094043887147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████▎                                                | 40/159 [00:19<00:18,  6.46it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 1.975705329153605\n",
      "This is the average difference: 2.0352664576802506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████▏                                               | 42/159 [00:20<00:17,  6.57it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.0893416927899686\n",
      "This is the average difference: 2.1371473354231973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████▉                                               | 44/159 [00:20<00:17,  6.64it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.195141065830721\n",
      "This is the average difference: 2.227272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████▊                                              | 46/159 [00:20<00:17,  6.51it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.2891849529780566\n",
      "This is the average difference: 2.3503134796238245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████▌                                             | 48/159 [00:20<00:16,  6.59it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.397335423197492\n",
      "This is the average difference: 2.4412225705329154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████▍                                            | 50/159 [00:21<00:16,  6.54it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.481191222570533\n",
      "This is the average difference: 2.5336990595611284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████▎                                           | 52/159 [00:21<00:16,  6.44it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.5752351097178683\n",
      "This is the average difference: 2.6253918495297808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████                                           | 54/159 [00:21<00:16,  6.40it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.69435736677116\n",
      "This is the average difference: 2.739811912225705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████▉                                          | 56/159 [00:22<00:16,  6.41it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.802507836990596\n",
      "This is the average difference: 2.8605015673981193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████▋                                         | 58/159 [00:22<00:15,  6.48it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.9004702194357366\n",
      "This is the average difference: 2.945141065830721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████▌                                        | 60/159 [00:22<00:15,  6.34it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 2.989028213166144\n",
      "This is the average difference: 3.043103448275862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████▎                                       | 62/159 [00:23<00:14,  6.57it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.084639498432602\n",
      "This is the average difference: 3.1426332288401255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████▏                                      | 64/159 [00:23<00:14,  6.63it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.1802507836990594\n",
      "This is the average difference: 3.239811912225705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████▉                                      | 66/159 [00:23<00:14,  6.43it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.2970219435736676\n",
      "This is the average difference: 3.3401253918495297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████▊                                     | 68/159 [00:24<00:14,  6.35it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.3996865203761755\n",
      "This is the average difference: 3.4420062695924765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████▌                                    | 70/159 [00:24<00:13,  6.45it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.500783699059561\n",
      "This is the average difference: 3.554075235109718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████▍                                   | 72/159 [00:24<00:13,  6.53it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.5893416927899686\n",
      "This is the average difference: 3.6496865203761755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████▎                                  | 74/159 [00:24<00:13,  6.42it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.706896551724138\n",
      "This is the average difference: 3.7405956112852663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████                                  | 76/159 [00:25<00:12,  6.54it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.804858934169279\n",
      "This is the average difference: 3.8557993730407523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████▉                                 | 78/159 [00:25<00:12,  6.35it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.90282131661442\n",
      "This is the average difference: 3.9482758620689653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████▋                                | 80/159 [00:25<00:12,  6.56it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 3.989028213166144\n",
      "This is the average difference: 4.017241379310345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████▌                               | 82/159 [00:26<00:11,  6.62it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.08307210031348\n",
      "This is the average difference: 4.11128526645768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████▎                              | 84/159 [00:26<00:11,  6.45it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.165360501567398\n",
      "This is the average difference: 4.209247648902822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████▏                             | 86/159 [00:26<00:11,  6.58it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.248432601880878\n",
      "This is the average difference: 4.304858934169279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████▉                             | 88/159 [00:27<00:10,  6.61it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.365987460815047\n",
      "This is the average difference: 4.40282131661442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████▊                            | 90/159 [00:27<00:10,  6.45it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.471003134796239\n",
      "This is the average difference: 4.509404388714733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████▌                           | 92/159 [00:27<00:10,  6.41it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.55564263322884\n",
      "This is the average difference: 4.610501567398119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████▍                          | 94/159 [00:28<00:09,  6.71it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.663009404388715\n",
      "This is the average difference: 4.710031347962382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████▏                         | 96/159 [00:28<00:09,  6.48it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.778213166144201\n",
      "This is the average difference: 4.815830721003135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████                         | 98/159 [00:28<00:09,  6.39it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.870689655172414\n",
      "This is the average difference: 4.925548589341693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████▎                       | 100/159 [00:28<00:09,  6.52it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 4.986677115987461\n",
      "This is the average difference: 5.045454545454546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████                       | 102/159 [00:29<00:08,  6.44it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.093260188087775\n",
      "This is the average difference: 5.139498432601881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████▊                      | 104/159 [00:29<00:08,  6.23it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.185736677115988\n",
      "This is the average difference: 5.222570532915361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████▋                     | 106/159 [00:29<00:08,  6.24it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.274294670846395\n",
      "This is the average difference: 5.336206896551724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████▍                    | 108/159 [00:30<00:08,  6.32it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.383228840125392\n",
      "This is the average difference: 5.419278996865204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████▎                   | 110/159 [00:30<00:08,  6.12it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.4576802507836994\n",
      "This is the average difference: 5.514890282131661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████                   | 112/159 [00:30<00:07,  6.17it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.5697492163009406\n",
      "This is the average difference: 5.630094043887147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████▉                  | 114/159 [00:31<00:06,  6.48it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.678683385579937\n",
      "This is the average difference: 5.718652037617555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████▋                 | 116/159 [00:31<00:06,  6.43it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.773510971786834\n",
      "This is the average difference: 5.824451410658307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████▍                | 118/159 [00:31<00:06,  6.42it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.872257053291536\n",
      "This is the average difference: 5.928683385579937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████▎               | 120/159 [00:32<00:06,  6.43it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 5.988244514106583\n",
      "This is the average difference: 6.039184952978056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████               | 122/159 [00:32<00:05,  6.44it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.093260188087775\n",
      "This is the average difference: 6.134012539184953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████▉              | 124/159 [00:32<00:05,  6.36it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.177899686520377\n",
      "This is the average difference: 6.225705329153605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████▋             | 126/159 [00:33<00:05,  6.50it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.286833855799373\n",
      "This is the average difference: 6.352664576802508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████▌            | 128/159 [00:33<00:04,  6.26it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.40282131661442\n",
      "This is the average difference: 6.4537617554858935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████▎           | 130/159 [00:33<00:04,  6.44it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.518025078369906\n",
      "This is the average difference: 6.579153605015674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████▏          | 132/159 [00:34<00:04,  6.33it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.62460815047022\n",
      "This is the average difference: 6.668495297805642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████▉          | 134/159 [00:34<00:03,  6.34it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.7272727272727275\n",
      "This is the average difference: 6.781347962382445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████▋         | 136/159 [00:34<00:03,  6.48it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.815830721003135\n",
      "This is the average difference: 6.862068965517241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████▌        | 138/159 [00:34<00:03,  6.52it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 6.925548589341693\n",
      "This is the average difference: 6.978056426332288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████▎       | 140/159 [00:35<00:02,  6.40it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.0\n",
      "This is the average difference: 7.058777429467084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████▏      | 142/159 [00:35<00:02,  6.35it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.106583072100314\n",
      "This is the average difference: 7.15987460815047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████▉      | 144/159 [00:35<00:02,  6.49it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.214733542319749\n",
      "This is the average difference: 7.256269592476489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████▊     | 146/159 [00:36<00:02,  6.31it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.313479623824452\n",
      "This is the average difference: 7.368338557993731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████▌    | 148/159 [00:36<00:01,  6.46it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.4043887147335425\n",
      "This is the average difference: 7.4537617554858935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████▍   | 150/159 [00:36<00:01,  6.37it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.524294670846395\n",
      "This is the average difference: 7.587774294670846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████▏  | 152/159 [00:37<00:01,  6.48it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.646551724137931\n",
      "This is the average difference: 7.698275862068965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████▉  | 154/159 [00:37<00:00,  6.59it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.745297805642633\n",
      "This is the average difference: 7.803291536050157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████▊ | 156/159 [00:37<00:00,  6.49it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.864420062695925\n",
      "This is the average difference: 7.898902821316614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████▌| 158/159 [00:38<00:00,  6.38it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 7.962382445141066\n",
      "This is the average difference: 8.0141065830721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 159/159 [00:38<00:00,  6.35it/s, test1.0 7.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average difference: 8.061128526645769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 159/159 [00:38<00:00,  4.12it/s, test1.0 7.0000]\n"
     ]
    }
   ],
   "source": [
    "#this is for large index\n",
    "\n",
    "num_epochs = 1\n",
    "verbose = True\n",
    "\n",
    "startingEpoch = 0\n",
    "startingBestLoss = 100000\n",
    "priorCheckpoint = os.path.join(outputpath, \"verbose_normalizedsmallindex_best2.pt\") # you need to load different weights\n",
    "\n",
    "toGPU = torch.cuda.is_available()\n",
    "#toGPU = False\n",
    "\n",
    "\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "\n",
    "if toGPU:\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "if os.path.exists(priorCheckpoint):   \n",
    "    if toGPU:\n",
    "        print(\"Loading Weights\")\n",
    "        checkpoint = torch.load(priorCheckpoint)\n",
    "        \n",
    "        \n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        model.eval()\n",
    "        \n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "    else:\n",
    "        print(\"cuda is not available, cpu weights\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        checkpoint = torch.load(priorCheckpoint, map_location = \"cpu\")\n",
    "        state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict_cpu)\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "        \n",
    "        \n",
    "logFilename = os.path.join(outputpath, \"scripts\", \"test_normalizedsmallindex.csv\")\n",
    "\n",
    "totaldiff = 0\n",
    "\n",
    "with open(logFilename, 'w') as output:\n",
    "    for epoch in range(1, 2):\n",
    "        for phase in dataloaders.keys():\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                    for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "                        \n",
    "                        #print(x, outcome)\n",
    "                        x = x.to(device)\n",
    "                        outcome = outcome.to(device)\n",
    "                        p = model(x)#[\"out\"]\n",
    "                        #output.write(#Filename, Prediction, GroundTruth, Difference betwen the two)\n",
    "                        \n",
    "                        for i in range(batch_size):\n",
    "                            output.write(str(round(p[i].item())) + \",\" + str(outcome[i].item()) + \",\" + str( abs(round(p[i].item()) - outcome[i].item())) + \"\\n\")\n",
    "                            #print(str(round(p[i].item())) + \",\" + str(outcome[i].item()) + \",\" + str( abs(round(p[i].item()) - outcome[i].item())))\n",
    "                            totaldiff += abs(round(p[i].item()) - outcome[i].item())\n",
    "                            std.append()\n",
    "                        #loss = torch.nn.functional.mse_loss(p.view(-1), outcome)\n",
    "\n",
    "                        progressbar.set_postfix_str(phase +\"{:.1f} {:.4f}\".format(epoch, i))\n",
    "                        progressbar.update()\n",
    "                        \n",
    "                        print(\"This is the average difference:\", totaldiff / 1276)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9694\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "totaldiff = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    #print(random.randint(0,32))\n",
    "    totaldiff += abs(random.randint(0,32) - random.randint(0,32))\n",
    "    \n",
    "print(totaldiff / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for large index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.08518  33.43475  34.045193] [49.781414 50.02839  50.6773  ]\n",
      "7460 1288\n"
     ]
    }
   ],
   "source": [
    "mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(split=\"train\"))\n",
    "print(mean,std)\n",
    "\n",
    "modelname=\"r2plus1d_18\"\n",
    "frames=32\n",
    "period=1\n",
    "tasks=\"NormalizedLargeIndex\"#\"NormalizedSmallIndex\"\n",
    "pretrained=True \n",
    "\n",
    "\n",
    "kwargs = {\"target_type\": tasks,\n",
    "              \"mean\": mean,\n",
    "              \"std\": std,\n",
    "              \"length\": frames,\n",
    "              \"period\": period,\n",
    "              }\n",
    "\n",
    "    # Set up datasets and dataloaders\n",
    "train_dataset = echonet.datasets.Echo(split=\"train\", **kwargs)\n",
    "\n",
    "val_dataset = echonet.datasets.Echo(split=\"val\", **kwargs)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWork = 5\n",
    "batch_size=8\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Set up model\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "# for phase in dataloaders.keys():\n",
    "#     with torch.set_grad_enabled(phase == \"train\"):\n",
    "#         with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "#             for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "#                 print(i, x.shape, outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 1/932 [00:22<5:49:15, 22.51s/it, train1.0 39.2122 (39.2122)]C:\\Users\\Remote\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:55<00:00,  1.42it/s, train1.0 10.5699 (9.0935)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:40<00:00,  3.96it/s, val1.0 9.6021 (8.3372)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train2.0 9.3867 (6.8829)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:40<00:00,  3.99it/s, val2.0 9.6272 (5.8500)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train3.0 9.4245 (13.2697)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:40<00:00,  4.02it/s, val3.0 9.0497 (11.1605)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train4.0 9.2424 (7.0322)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val4.0 9.1678 (11.9890)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train5.0 9.3704 (7.8098)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val5.0 9.4511 (7.7117)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train6.0 9.3616 (12.8696)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.16it/s, val6.0 9.4329 (13.2467)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train7.0 9.4197 (12.5545)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val7.0 9.3271 (4.1860)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train8.0 9.5281 (7.6946)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val8.0 9.3723 (3.5243)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train9.0 9.2937 (11.7168)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val9.0 9.4275 (12.2757)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train10.0 9.3985 (18.4731)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val10.0 9.5247 (9.3961)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train11.0 9.5760 (11.6652)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val11.0 9.6775 (9.6470)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train12.0 9.4461 (7.8833)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val12.0 9.3063 (8.2390)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train13.0 9.3755 (7.0769)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val13.0 9.9742 (14.9442)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train14.0 9.5243 (12.9422)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val14.0 9.5599 (6.7630)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train15.0 9.3565 (5.9968)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val15.0 9.3066 (10.4711)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train16.0 9.5652 (11.0512)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val16.0 9.3364 (8.2364)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train17.0 9.5190 (8.0582)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val17.0 9.5040 (9.0086)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train18.0 9.3484 (5.3513)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val18.0 9.9341 (13.5845)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train19.0 9.1120 (11.8994)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val19.0 9.2576 (11.9599)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train20.0 9.4892 (10.2806)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val20.0 9.5915 (11.0372)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train21.0 9.3519 (6.4354)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val21.0 9.9301 (12.6137)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train22.0 9.3010 (4.3986)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val22.0 9.5300 (11.5710)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train23.0 9.3342 (7.6771)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.16it/s, val23.0 9.6528 (13.5909)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train24.0 9.2691 (11.7540)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val24.0 10.0317 (8.7850)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train25.0 9.4178 (13.2196)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val25.0 9.5994 (8.7017)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train26.0 9.4075 (3.3041)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val26.0 9.4927 (6.2533)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train27.0 9.5402 (7.9910)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val27.0 9.5568 (7.9223)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train28.0 9.5434 (14.3374)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val28.0 9.3111 (9.8492)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train29.0 9.2757 (8.9483)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val29.0 9.3412 (5.6710)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train30.0 9.3907 (16.5554)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val30.0 9.7095 (10.8141)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train31.0 9.4638 (2.8242)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val31.0 9.5240 (5.6235)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train32.0 9.5097 (4.2920)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val32.0 9.1149 (11.0471)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train33.0 9.4476 (10.1639)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val33.0 9.4362 (14.5925)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train34.0 9.5201 (7.9722)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val34.0 9.0594 (8.0951)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train35.0 9.2064 (8.0449)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val35.0 9.5380 (4.7359)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train36.0 9.4207 (10.8948)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val36.0 9.7520 (8.8953)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train37.0 9.5147 (14.5106)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val37.0 9.2919 (8.7698)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train38.0 9.4081 (14.1128)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val38.0 9.6998 (12.3921)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train39.0 9.4747 (5.6430)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.16it/s, val39.0 9.6936 (6.5347)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train40.0 9.4103 (12.0689)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val40.0 9.6415 (8.7911)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train41.0 9.4379 (12.3463)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val41.0 9.1665 (11.7129)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train42.0 9.3598 (10.7813)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val42.0 9.6153 (15.5064)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train43.0 9.3917 (11.9317)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val43.0 9.4838 (10.0931)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train44.0 9.4078 (7.9987)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val44.0 9.5673 (8.5705)]\n"
     ]
    }
   ],
   "source": [
    "#this is for large index\n",
    "\n",
    "num_epochs = 45\n",
    "verbose = True\n",
    "\n",
    "startingEpoch = 0\n",
    "startingBestLoss = 100000\n",
    "priorCheckpoint =  os.path.join(outputpath, \"verbose_normalizedlargeindex_checkpoint.pt\")\n",
    "\n",
    "toGPU = torch.cuda.is_available()\n",
    "#toGPU = False\n",
    "if toGPU:\n",
    "    print(\"cuda is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "if os.path.exists(priorCheckpoint):   \n",
    "    if toGPU:\n",
    "        print(\"loading weights\")\n",
    "        checkpoint = torch.load(priorCheckpoint)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "    else:\n",
    "        print(\"cuda is not available, cpu weights\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        checkpoint = torch.load(priorCheckpoint, map_location = \"cpu\")\n",
    "        state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict_cpu)\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "learning_rate = 1e-4\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "bestLoss = startingBestLoss\n",
    "priorLines = None\n",
    "logFilename = os.path.join(outputpath, \"scripts\", \"verbose_normalizedlargeindex.csv\")\n",
    "if os.path.exists(logFilename):\n",
    "    with open(logFilename, 'r') as output:\n",
    "        priorLines = output.readlines()\n",
    "else:\n",
    "    if not os.path.exists(os.path.join(outputpath, \"scripts\")):\n",
    "        os.mkdir(os.path.join(outputpath, \"scripts\"))\n",
    "\n",
    "with open(logFilename, 'w') as output:\n",
    "    for epoch in range(startingEpoch + 1, num_epochs):\n",
    "        if priorLines is not None:\n",
    "            for line in priorLines:\n",
    "                output.write(line)\n",
    "                print(line)\n",
    "        for phase in dataloaders.keys():\n",
    "            total = 0\n",
    "            n = 0\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                    for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "\n",
    "                        x = x.to(device)\n",
    "                        outcome = outcome.to(device)\n",
    "                        p = model(x)#[\"out\"]\n",
    "\n",
    "                        loss = torch.nn.functional.mse_loss(p.view(-1), outcome)\n",
    "                        \n",
    "                        total += loss.item()\n",
    "                        n += x.shape[0]\n",
    "                        progressbar.set_postfix_str(phase +\"{:.1f} {:.4f} ({:.4f})\".format(epoch, total / n, loss.item() /  x.shape[0]))\n",
    "                        progressbar.update()\n",
    "                        if(phase == 'train'):\n",
    "                            optim.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optim.step()\n",
    "            output.write(phase + \",\" + str(epoch) + \",\" + str(total/n) + \"\\n\")\n",
    "            output.flush()\n",
    "            save = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'period': period,\n",
    "                'frames':frames,\n",
    "                'best_loss': bestLoss,\n",
    "                'loss': total / n,\n",
    "                'opt_dict': optim.state_dict()\n",
    "                }\n",
    "            torch.save(save, os.path.join(outputpath, \"verbose_normalizedlargeindex_checkpoint.pt\"))\n",
    "            if total / n < bestLoss and phase == \"val\":\n",
    "                torch.save(save, os.path.join(outputpath, \"verbose_normalizedlargeindex_best.pt\"))\n",
    "                bestLoss = total / n\n",
    "                print(\"This is the best yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.415447 33.460274 33.60476 ] [50.284832 50.356934 50.523277]\n",
      "7460 1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 1/932 [00:13<3:29:44, 13.52s/it, train1.0 36.9018 (36.9018)]C:\\Users\\Remote\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:35<00:00,  1.47it/s, train1.0 10.8496 (10.8531)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val1.0 9.6554 (11.3109)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train2.0 9.3447 (7.5669)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val2.0 9.5841 (11.5499)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:41<00:00,  1.45it/s, train3.0 9.4003 (7.8230)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val3.0 9.7828 (9.3096)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train4.0 9.5732 (5.5563)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val4.0 9.6093 (4.6943)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train5.0 9.3135 (12.1473)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val5.0 9.2532 (15.6613)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train6.0 9.3167 (8.8281)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val6.0 9.8685 (6.5751)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:41<00:00,  1.45it/s, train7.0 9.6474 (6.6754)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val7.0 9.5389 (13.0334)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train8.0 9.5013 (9.1811)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val8.0 9.6375 (7.6152)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train9.0 9.4796 (8.7215)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:41<00:00,  3.92it/s, val9.0 9.0699 (5.0940)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train10.0 9.5562 (8.5034)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val10.0 9.6136 (11.2456)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train11.0 9.3343 (9.6457)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val11.0 9.3382 (9.7912)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train12.0 9.4387 (6.9750)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.04it/s, val12.0 9.5351 (9.7726)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train13.0 9.4568 (11.8710)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:40<00:00,  3.98it/s, val13.0 9.6047 (6.7074)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train14.0 9.3520 (8.4383)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.04it/s, val14.0 9.2167 (7.1272)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train15.0 9.5668 (10.9723)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.04it/s, val15.0 9.5247 (11.3817)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train16.0 9.3806 (12.1698)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val16.0 9.0650 (14.7674)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train17.0 9.2654 (7.6176)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val17.0 9.5418 (8.8998)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:39<00:00,  1.46it/s, train18.0 9.3004 (14.2950)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:40<00:00,  3.99it/s, val18.0 9.3123 (12.5503)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train19.0 9.4195 (9.9566)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val19.0 9.5110 (5.6416)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train20.0 9.5243 (10.9866)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.05it/s, val20.0 9.4624 (7.1388)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train21.0 9.5821 (12.9623)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val21.0 9.1204 (14.2296)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train22.0 9.4081 (9.2882)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val22.0 9.5453 (10.1780)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:41<00:00,  1.45it/s, train23.0 9.4903 (7.3188)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val23.0 9.5231 (4.9978)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:41<00:00,  1.45it/s, train24.0 9.1369 (11.6475)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val24.0 9.4230 (7.8796)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train25.0 9.5783 (8.3878)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.05it/s, val25.0 9.2644 (11.2487)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train26.0 9.4082 (10.7072)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val26.0 9.3255 (13.2676)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train27.0 9.4465 (6.3468)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val27.0 9.5526 (13.3239)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train28.0 9.3588 (9.2941)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.06it/s, val28.0 9.7643 (7.7569)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train29.0 9.4626 (12.2548)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val29.0 9.2668 (12.1058)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train30.0 9.2657 (3.3478)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val30.0 9.1310 (10.1508)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train31.0 9.4108 (11.3645)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val31.0 9.5487 (9.9670)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train32.0 9.4070 (9.9544)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val32.0 9.3373 (7.5517)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train33.0 9.2383 (4.3146)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.06it/s, val33.0 9.3411 (9.1718)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train34.0 9.5948 (9.5564)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val34.0 9.4248 (6.1237)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train35.0 9.5574 (11.6830)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.06it/s, val35.0 9.3924 (6.5535)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train36.0 9.4239 (10.0490)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.05it/s, val36.0 9.4093 (9.1152)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train37.0 9.6129 (9.7149)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val37.0 9.4600 (7.4228)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train38.0 9.1510 (7.7342)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.05it/s, val38.0 9.4417 (9.8683)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train39.0 9.4150 (8.9865)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val39.0 9.5734 (9.8494)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train40.0 9.4081 (5.6736)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val40.0 9.5510 (5.8255)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train41.0 9.4717 (8.6343)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val41.0 9.4570 (11.2191)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train42.0 9.3884 (5.1548)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val42.0 9.4005 (9.1188)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:41<00:00,  1.45it/s, train43.0 9.5249 (9.9889)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.06it/s, val43.0 9.4447 (7.2572)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train44.0 9.3444 (11.8916)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val44.0 9.3188 (5.3197)]\n"
     ]
    }
   ],
   "source": [
    "mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(split=\"train\"))\n",
    "print(mean,std)\n",
    "\n",
    "modelname=\"r3d_18\"\n",
    "frames=32\n",
    "period=1\n",
    "tasks=\"NormalizedLargeIndex\"#\"NormalizedSmallIndex\"\n",
    "pretrained=True \n",
    "\n",
    "\n",
    "kwargs = {\"target_type\": tasks,\n",
    "              \"mean\": mean,\n",
    "              \"std\": std,\n",
    "              \"length\": frames,\n",
    "              \"period\": period,\n",
    "              }\n",
    "\n",
    "    # Set up datasets and dataloaders\n",
    "train_dataset = echonet.datasets.Echo(split=\"train\", **kwargs)\n",
    "\n",
    "val_dataset = echonet.datasets.Echo(split=\"val\", **kwargs)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "\n",
    "numWork = 5\n",
    "batch_size=8\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Set up model\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "# for phase in dataloaders.keys():\n",
    "#     with torch.set_grad_enabled(phase == \"train\"):\n",
    "#         with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "#             for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "#                 print(i, x.shape, outcome)\n",
    "\n",
    "\n",
    "#this is for large index\n",
    "\n",
    "num_epochs = 45\n",
    "verbose = True\n",
    "\n",
    "startingEpoch = 0\n",
    "startingBestLoss = 100000\n",
    "priorCheckpoint =  os.path.join(outputpath, \"verbose_r3d_normalizedlargeindex_checkpoint.pt\")\n",
    "\n",
    "toGPU = torch.cuda.is_available()\n",
    "#toGPU = False\n",
    "if toGPU:\n",
    "    print(\"cuda is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "if os.path.exists(priorCheckpoint):   \n",
    "    if toGPU:\n",
    "        print(\"loading weights\")\n",
    "        checkpoint = torch.load(priorCheckpoint)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "    else:\n",
    "        print(\"cuda is not available, cpu weights\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        checkpoint = torch.load(priorCheckpoint, map_location = \"cpu\")\n",
    "        state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict_cpu)\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "learning_rate = 1e-4\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "bestLoss = startingBestLoss\n",
    "priorLines = None\n",
    "logFilename = os.path.join(outputpath, \"scripts\", \"verbose_r3d_normalizedlargeindex.csv\")\n",
    "if os.path.exists(logFilename):\n",
    "    with open(logFilename, 'r') as output:\n",
    "        priorLines = output.readlines()\n",
    "else:\n",
    "    if not os.path.exists(os.path.join(outputpath, \"scripts\")):\n",
    "        os.mkdir(os.path.join(outputpath, \"scripts\"))\n",
    "# with open(logFilename, 'w') as output:\n",
    "#     for line in priorLines:\n",
    "#         output.write(line)\n",
    "with open(logFilename, 'w') as output:\n",
    "    for epoch in range(startingEpoch + 1, num_epochs):\n",
    "        if priorLines is not None:\n",
    "            for line in priorLines:\n",
    "                output.write(line)\n",
    "                print(line)\n",
    "        for phase in dataloaders.keys():\n",
    "            total = 0\n",
    "            n = 0\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                    for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "#                         if verbose:\n",
    "#                             print(i, x.shape, outcome)\n",
    "                        x = x.to(device)\n",
    "                        outcome = outcome.to(device)\n",
    "                        p = model(x)#[\"out\"]\n",
    "#                         if verbose:\n",
    "#                             print( x.shape, p.shape, outcome.shape)\n",
    "                            \n",
    "                        loss = torch.nn.functional.mse_loss(p.view(-1), outcome)\n",
    "                        \n",
    "                        total += loss.item()\n",
    "                        n += x.shape[0]\n",
    "                        progressbar.set_postfix_str(phase +\"{:.1f} {:.4f} ({:.4f})\".format(epoch, total / n, loss.item() /  x.shape[0]))\n",
    "                        progressbar.update()\n",
    "                        if(phase == 'train'):\n",
    "                            optim.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optim.step()\n",
    "            output.write(phase + \",\" + str(epoch) + \",\" + str(total/n) + \"\\n\")\n",
    "            output.flush()\n",
    "            save = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'period': period,\n",
    "                'frames':frames,\n",
    "                'best_loss': bestLoss,\n",
    "                'loss': total / n,\n",
    "                'opt_dict': optim.state_dict()\n",
    "                }\n",
    "            torch.save(save, os.path.join(outputpath, \"verbose_r3d_normalizedlargeindex_checkpoint.pt\"))\n",
    "            if total / n < bestLoss and phase == \"val\":\n",
    "                torch.save(save, os.path.join(outputpath, \"verbose_r3d_normalizedlargeindex_best.pt\"))\n",
    "                bestLoss = total / n\n",
    "                print(\"This is the best yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Remote\\Documents\\ishanjain\\echonet-function-evaluation\\Deep Learning\\output\\video\\r2plus1d_18_32_1_pretrained\\verbose_classification_normalizedlargeindex_checkpoint.pt False\n",
      "cuda is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train1.0 0.4324 (0.4218)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val1.0 0.4307 (0.4283)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train2.0 0.4306 (0.4172)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val2.0 0.4293 (0.4348)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train3.0 0.4303 (0.4292)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val3.0 0.4297 (0.4470)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train4.0 0.4298 (0.4238)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val4.0 0.4306 (0.4249)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train5.0 0.4296 (0.4356)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val5.0 0.4302 (0.4373)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train6.0 0.4300 (0.4279)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val6.0 0.4287 (0.4259)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train7.0 0.4298 (0.4355)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.04it/s, val7.0 0.4291 (0.4302)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train8.0 0.4289 (0.4153)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val8.0 0.4289 (0.4122)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train9.0 0.4297 (0.4269)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.05it/s, val9.0 0.4288 (0.4252)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train10.0 0.4293 (0.4319)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val10.0 0.4292 (0.4132)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train11.0 0.4293 (0.4316)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val11.0 0.4296 (0.4287)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train12.0 0.4291 (0.4191)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val12.0 0.4294 (0.4273)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train13.0 0.4296 (0.4239)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val13.0 0.4298 (0.4314)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train14.0 0.4296 (0.4300)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val14.0 0.4290 (0.4307)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train15.0 0.4289 (0.4303)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val15.0 0.4295 (0.4309)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train16.0 0.4294 (0.4333)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:40<00:00,  4.02it/s, val16.0 0.4295 (0.4264)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:40<00:00,  1.45it/s, train17.0 0.4290 (0.4295)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val17.0 0.4287 (0.4197)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train18.0 0.4293 (0.4243)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val18.0 0.4288 (0.4309)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train19.0 0.4289 (0.4244)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val19.0 0.4292 (0.4250)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train20.0 0.4295 (0.4224)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val20.0 0.4288 (0.4282)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train21.0 0.4292 (0.4246)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val21.0 0.4293 (0.4314)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train22.0 0.4293 (0.4203)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val22.0 0.4292 (0.4225)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train23.0 0.4294 (0.4357)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val23.0 0.4292 (0.4310)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train24.0 0.4295 (0.4238)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val24.0 0.4283 (0.4325)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train25.0 0.4291 (0.4306)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val25.0 0.4283 (0.4156)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train26.0 0.4287 (0.4356)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val26.0 0.4290 (0.4364)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train27.0 0.4293 (0.4299)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.05it/s, val27.0 0.4286 (0.4301)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:41<00:00,  1.45it/s, train28.0 0.4292 (0.4236)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val28.0 0.4293 (0.4353)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train29.0 0.4290 (0.4301)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val29.0 0.4297 (0.4393)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train30.0 0.4291 (0.4208)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val30.0 0.4286 (0.4342)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train31.0 0.4294 (0.4229)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val31.0 0.4292 (0.4262)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train32.0 0.4292 (0.4317)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val32.0 0.4287 (0.4331)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train33.0 0.4289 (0.4210)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val33.0 0.4286 (0.4281)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train34.0 0.4292 (0.4319)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val34.0 0.4290 (0.4270)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train35.0 0.4288 (0.4206)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val35.0 0.4291 (0.4301)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train36.0 0.4290 (0.4328)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.05it/s, val36.0 0.4292 (0.4335)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train37.0 0.4295 (0.4275)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val37.0 0.4288 (0.4264)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train38.0 0.4292 (0.4920)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val38.0 0.4287 (0.4299)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train39.0 0.4291 (0.4257)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val39.0 0.4286 (0.4309)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train40.0 0.4293 (0.4237)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val40.0 0.4290 (0.4297)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train41.0 0.4291 (0.4236)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val41.0 0.4298 (0.4252)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train42.0 0.4284 (0.4258)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val42.0 0.4285 (0.4306)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:42<00:00,  1.45it/s, train43.0 0.4292 (0.4311)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val43.0 0.4295 (0.4262)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train44.0 0.4283 (0.4230)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val44.0 0.4288 (0.4253)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is for large index\n",
    "# Classification task instead of regression task on frame number\n",
    "\n",
    "# Changed model, with num classes as number of frames, and changed into cross entropy task and one_hot encoding of classes\n",
    "\n",
    "\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False, num_classes = frames)\n",
    "#model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 45\n",
    "verbose = True\n",
    "\n",
    "startingEpoch = 0\n",
    "startingBestLoss = 100000\n",
    "priorCheckpoint =  os.path.join(outputpath, \"verbose_classification_normalizedlargeindex_checkpoint.pt\")\n",
    "print(priorCheckpoint, os.path.exists(priorCheckpoint))\n",
    "\n",
    "toGPU = torch.cuda.is_available()\n",
    "#toGPU = False\n",
    "if toGPU:\n",
    "    print(\"cuda is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "if os.path.exists(priorCheckpoint):   \n",
    "    if toGPU:\n",
    "        print(\"loading weights\")\n",
    "        checkpoint = torch.load(priorCheckpoint)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "    else:\n",
    "        print(\"cuda is not available, cpu weights\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        checkpoint = torch.load(priorCheckpoint, map_location = \"cpu\")\n",
    "        state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict_cpu)\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "learning_rate = 1e-4\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "bestLoss = startingBestLoss\n",
    "priorLines = None\n",
    "logFilename = os.path.join(outputpath, \"scripts\", \"verbose_classification_normalizedlargeindex.csv\")\n",
    "if os.path.exists(logFilename):\n",
    "    with open(logFilename, 'r') as output:\n",
    "        priorLines = output.readlines()\n",
    "else:\n",
    "    if not os.path.exists( os.path.join(outputpath, \"scripts\")):\n",
    "        os.mkdir(os.path.join(outputpath, \"scripts\"))\n",
    "# with open(logFilename, 'w') as output:\n",
    "#     for line in priorLines:\n",
    "#         output.write(line)\n",
    "with open(logFilename, 'w') as output:\n",
    "    for epoch in range(startingEpoch + 1, num_epochs):\n",
    "        if priorLines is not None:\n",
    "            for line in priorLines:\n",
    "                output.write(line)\n",
    "                print(line)\n",
    "        for phase in dataloaders.keys():\n",
    "            total = 0\n",
    "            n = 0\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                    for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "                        \n",
    "    \n",
    "#                         if verbose:\n",
    "#                             print(i, outcome, outcome.type(torch.int64))\n",
    "                        \n",
    "#                         #one hot encoding of outcome, also needs to be int instead of double to use one_hot\n",
    "                        \n",
    "#                         one_hot = torch.nn.functional.one_hot(outcome.type(torch.int64), num_classes = frames)\n",
    "\n",
    "#                         if verbose:\n",
    "#                             print(i, x.shape, outcome.shape, one_hot.shape)\n",
    "                        \n",
    "                        x = x.to(device)\n",
    "                        outcome = outcome.to(device)\n",
    "                        #one_hot = one_hot.to(device)\n",
    "                        p = model(x)#[\"out\"]\n",
    "#                         if verbose:\n",
    "#                             print( x.shape, p.shape, outcome.shape)\n",
    "                        \n",
    "    \n",
    "                        loss = torch.nn.functional.cross_entropy(p, outcome.type(torch.int64)) #one_hot)\n",
    "                        \n",
    "                        total += loss.item()\n",
    "                        n += x.shape[0]\n",
    "                        progressbar.set_postfix_str(phase +\"{:.1f} {:.4f} ({:.4f})\".format(epoch, total / n, loss.item() /  x.shape[0]))\n",
    "                        progressbar.update()\n",
    "                        if(phase == 'train'):\n",
    "                            optim.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optim.step()\n",
    "            output.write(phase + \",\" + str(epoch) + \",\" + str(total/n) + \"\\n\")\n",
    "            output.flush()\n",
    "            save = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'period': period,\n",
    "                'frames':frames,\n",
    "                'best_loss': bestLoss,\n",
    "                'loss': total / n,\n",
    "                'opt_dict': optim.state_dict()\n",
    "                }\n",
    "            torch.save(save, os.path.join(outputpath, \"verbose_classification_normalizedlargeindex_checkpoint.pt\"))\n",
    "            if total / n < bestLoss and phase == \"val\":\n",
    "                torch.save(save, os.path.join(outputpath, \"verbose_classification_normalizedlargeindex_best.pt\"))\n",
    "                bestLoss = total / n\n",
    "                print(\"This is the best yet\")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This is for large index\n",
    "# Classification task instead of regression task on frame number\n",
    "\n",
    "# Changed model, with num classes as number of frames, and changed into cross entropy task and one_hot encoding of classes\n",
    "\n",
    "\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False, num_classes = frames)\n",
    "#model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 45\n",
    "verbose = True\n",
    "\n",
    "startingEpoch = 0\n",
    "startingBestLoss = 100000\n",
    "priorCheckpoint =  os.path.join(outputpath, \"verbose_classification_normalizedlargeindex_checkpoint.pt\")\n",
    "print(priorCheckpoint, os.path.exists(priorCheckpoint))\n",
    "\n",
    "toGPU = torch.cuda.is_available()\n",
    "#toGPU = False\n",
    "if toGPU:\n",
    "    print(\"cuda is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "if os.path.exists(priorCheckpoint):   \n",
    "    if toGPU:\n",
    "        print(\"loading weights\")\n",
    "        checkpoint = torch.load(priorCheckpoint)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "    else:\n",
    "        print(\"cuda is not available, cpu weights\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        checkpoint = torch.load(priorCheckpoint, map_location = \"cpu\")\n",
    "        state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict_cpu)\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "learning_rate = 1e-4\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "bestLoss = startingBestLoss\n",
    "priorLines = None\n",
    "logFilename = os.path.join(outputpath, \"scripts\", \"verbose_classification_normalizedlargeindex.csv\")\n",
    "if os.path.exists(logFilename):\n",
    "    with open(logFilename, 'r') as output:\n",
    "        priorLines = output.readlines()\n",
    "else:\n",
    "    if not os.path.exists( os.path.join(outputpath, \"scripts\")):\n",
    "        os.mkdir(os.path.join(outputpath, \"scripts\"))\n",
    "# with open(logFilename, 'w') as output:\n",
    "#     for line in priorLines:\n",
    "#         output.write(line)\n",
    "with open(logFilename, 'w') as output:\n",
    "    for epoch in range(startingEpoch + 1, num_epochs):\n",
    "        if priorLines is not None:\n",
    "            for line in priorLines:\n",
    "                output.write(line)\n",
    "                print(line)\n",
    "        for phase in dataloaders.keys():\n",
    "            total = 0\n",
    "            n = 0\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                    for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "                        \n",
    "    \n",
    "#                         if verbose:\n",
    "#                             print(i, outcome, outcome.type(torch.int64))\n",
    "                        \n",
    "#                         #one hot encoding of outcome, also needs to be int instead of double to use one_hot\n",
    "                        \n",
    "#                         one_hot = torch.nn.functional.one_hot(outcome.type(torch.int64), num_classes = frames)\n",
    "\n",
    "#                         if verbose:\n",
    "#                             print(i, x.shape, outcome.shape, one_hot.shape)\n",
    "                        \n",
    "                        x = x.to(device)\n",
    "                        outcome = outcome.to(device)\n",
    "                        #one_hot = one_hot.to(device)\n",
    "                        p = model(x)#[\"out\"]\n",
    "#                         if verbose:\n",
    "#                             print( x.shape, p.shape, outcome.shape)\n",
    "                        \n",
    "    \n",
    "                        loss = torch.nn.functional.cross_entropy(p, outcome.type(torch.int64)) #one_hot)\n",
    "                        \n",
    "                        total += loss.item()\n",
    "                        n += x.shape[0]\n",
    "                        progressbar.set_postfix_str(phase +\"{:.1f} {:.4f} ({:.4f})\".format(epoch, total / n, loss.item() /  x.shape[0]))\n",
    "                        progressbar.update()\n",
    "                        if(phase == 'train'):\n",
    "                            optim.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optim.step()\n",
    "            output.write(phase + \",\" + str(epoch) + \",\" + str(total/n) + \"\\n\")\n",
    "            output.flush()\n",
    "            save = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'period': period,\n",
    "                'frames':frames,\n",
    "                'best_loss': bestLoss,\n",
    "                'loss': total / n,\n",
    "                'opt_dict': optim.state_dict()\n",
    "                }\n",
    "            torch.save(save, os.path.join(outputpath, \"verbose_classification_normalizedlargeindex_checkpoint.pt\"))\n",
    "            if total / n < bestLoss and phase == \"val\":\n",
    "                torch.save(save, os.path.join(outputpath, \"verbose_classification_normalizedlargeindex_best.pt\"))\n",
    "                bestLoss = total / n\n",
    "                print(\"This is the best yet\")\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for small index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.148865 32.46407  32.90127 ] [49.9002   50.190792 50.71088 ]\n",
      "7460 1288\n"
     ]
    }
   ],
   "source": [
    "mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(split=\"train\"))\n",
    "print(mean,std)\n",
    "\n",
    "modelname=\"r2plus1d_18\"\n",
    "frames=32\n",
    "period=1\n",
    "tasks=\"NormalizedSmallIndex\"\n",
    "pretrained=True \n",
    "\n",
    "\n",
    "kwargs = {\"target_type\": tasks,\n",
    "              \"mean\": mean,\n",
    "              \"std\": std,\n",
    "              \"length\": frames,\n",
    "              \"period\": period,\n",
    "              }\n",
    "\n",
    "    # Set up datasets and dataloaders\n",
    "train_dataset = echonet.datasets.Echo(split=\"train\", **kwargs)\n",
    "\n",
    "val_dataset = echonet.datasets.Echo(split=\"val\", **kwargs)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWork = 5\n",
    "batch_size=8\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Set up model\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "# for phase in dataloaders.keys():\n",
    "#     with torch.set_grad_enabled(phase == \"train\"):\n",
    "#         with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "#             for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "#                 print(i, x.shape, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA False\n",
      "cuda is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 1/932 [00:18<4:45:47, 18.42s/it, train1.0 54.2464 (54.2464)]C:\\Users\\Remote\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:51<00:00,  1.43it/s, train1.0 12.3651 (12.3550)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.03it/s, val1.0 10.8758 (4.1186)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:47<00:00,  1.44it/s, train2.0 11.1296 (7.0590)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val2.0 11.1826 (7.5379)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train3.0 10.9904 (11.0428)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.06it/s, val3.0 10.9825 (9.9674)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train4.0 11.1689 (13.3262)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.17it/s, val4.0 10.5015 (13.7621)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train5.0 11.1877 (4.8209)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val5.0 10.8225 (10.0296)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train6.0 10.9611 (7.6683)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val6.0 10.9536 (9.8947)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train7.0 11.0626 (10.9001)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val7.0 11.0741 (10.1751)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train8.0 11.2284 (16.7163)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val8.0 10.2810 (7.0944)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train9.0 11.0824 (18.0659)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val9.0 10.5452 (10.7676)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train10.0 11.2435 (13.3574)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val10.0 11.0112 (10.5056)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train11.0 11.1898 (6.0899)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val11.0 10.5905 (14.9162)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train12.0 11.0478 (8.4186)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val12.0 11.3638 (17.3867)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train13.0 11.2627 (8.0653)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val13.0 11.2588 (8.7268)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train14.0 11.0742 (11.7800)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val14.0 11.2476 (11.7867)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train15.0 11.2231 (10.5759)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val15.0 10.5369 (13.3491)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train16.0 11.0558 (8.7129)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val16.0 10.9020 (17.8261)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train17.0 11.1328 (11.6218)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.06it/s, val17.0 10.8380 (12.3864)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:40<00:00,  1.45it/s, train18.0 11.0446 (7.4055)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val18.0 10.4252 (15.7959)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train19.0 11.1791 (11.4273)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val19.0 10.4392 (12.2094)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train20.0 10.9189 (6.8834)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val20.0 10.6085 (11.9101)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train21.0 11.2577 (10.3725)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.17it/s, val21.0 10.5230 (11.5190)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train22.0 11.1684 (10.7204)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val22.0 10.7890 (6.1015)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train23.0 11.1665 (10.3136)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val23.0 11.1110 (15.1429)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train24.0 11.2043 (8.2586)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val24.0 10.3982 (9.3129)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train25.0 11.2587 (11.6278)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val25.0 10.5729 (8.4227)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train26.0 11.1262 (6.3689)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val26.0 10.9953 (4.3915)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train27.0 11.1002 (12.3555)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val27.0 10.7646 (10.1958)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train28.0 11.1630 (14.0276)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val28.0 10.5893 (10.5146)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train29.0 11.2879 (7.7678)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val29.0 10.4354 (11.0115)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train30.0 11.1361 (10.8713)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val30.0 10.7407 (13.9354)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train31.0 11.3462 (9.0501)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val31.0 11.0470 (6.2928)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train32.0 11.2631 (5.8938)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val32.0 11.1191 (9.1238)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train33.0 11.1482 (6.1905)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val33.0 11.3208 (8.6913)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train34.0 11.2813 (11.1251)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val34.0 10.1946 (5.8289)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train35.0 11.0985 (13.0105)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val35.0 11.1413 (5.5422)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train36.0 11.1919 (6.8498)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val36.0 10.9996 (8.4919)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train37.0 11.2739 (10.1821)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val37.0 10.6825 (9.2260)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train38.0 11.1231 (14.2294)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val38.0 10.5861 (5.3399)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train39.0 11.1118 (5.7984)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val39.0 11.0461 (13.3718)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train40.0 11.0318 (9.0130)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val40.0 10.6374 (12.3707)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train41.0 11.1861 (12.0728)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val41.0 11.1746 (12.5438)]\n",
      "100%|████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train42.0 11.0900 (9.6029)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val42.0 10.7233 (12.1391)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train43.0 10.9358 (14.5923)]\n",
      "100%|█████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val43.0 10.8468 (11.0098)]\n",
      "100%|███████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train44.0 11.2928 (11.3907)]\n",
      "100%|██████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val44.0 10.7642 (8.4007)]\n"
     ]
    }
   ],
   "source": [
    "# This is for small index\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 45\n",
    "verbose = True\n",
    "\n",
    "startingEpoch = 0\n",
    "startingBestLoss = 100000\n",
    "priorCheckpoint =  os.path.join(outputpath, \"verbose_normalizedsmallindex_checkpoint.pt\")\n",
    "priorCheckpoint = \"NA\"\n",
    "print(priorCheckpoint, os.path.exists(priorCheckpoint))\n",
    "\n",
    "toGPU = torch.cuda.is_available()\n",
    "#toGPU = False\n",
    "if toGPU:\n",
    "    print(\"cuda is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "if os.path.exists(priorCheckpoint):   \n",
    "    if toGPU:\n",
    "        print(\"loading weights\")\n",
    "        checkpoint = torch.load(priorCheckpoint)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "    else:\n",
    "        print(\"cuda is not available, cpu weights\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        checkpoint = torch.load(priorCheckpoint, map_location = \"cpu\")\n",
    "        state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict_cpu)\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "learning_rate = 1e-4\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "bestLoss = startingBestLoss\n",
    "priorLines = None\n",
    "logFilename = os.path.join(outputpath, \"scripts\", \"verbose_normalizedsmallindex.csv\")\n",
    "if os.path.exists(logFilename):\n",
    "    with open(logFilename, 'r') as output:\n",
    "        priorLines = output.readlines()\n",
    "else:\n",
    "    os.mkdir(os.path.join(outputpath, \"scripts\"))\n",
    "# with open(logFilename, 'w') as output:\n",
    "#     for line in priorLines:\n",
    "#         output.write(line)\n",
    "with open(logFilename, 'w') as output:\n",
    "    for epoch in range(startingEpoch + 1, num_epochs):\n",
    "        if priorLines is not None:\n",
    "            for line in priorLines:\n",
    "                output.write(line)\n",
    "                print(line)\n",
    "        for phase in dataloaders.keys():\n",
    "            total = 0\n",
    "            n = 0\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                    for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "#                         if verbose:\n",
    "#                             print(i, x.shape, outcome.shape)\n",
    "                        x = x.to(device)\n",
    "                        outcome = outcome.to(device)\n",
    "                        p = model(x)#[\"out\"]\n",
    "#                         if verbose:\n",
    "#                             print( x.shape, p.shape, outcome.shape)\n",
    "                            \n",
    "                        loss = torch.nn.functional.mse_loss(p.view(-1), outcome)\n",
    "                        \n",
    "                        total += loss.item()\n",
    "                        n += x.shape[0]\n",
    "                        progressbar.set_postfix_str(phase +\"{:.1f} {:.4f} ({:.4f})\".format(epoch, total / n, loss.item() /  x.shape[0]))\n",
    "                        progressbar.update()\n",
    "                        if(phase == 'train'):\n",
    "                            optim.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optim.step()\n",
    "            output.write(phase + \",\" + str(epoch) + \",\" + str(total/n) + \"\\n\")\n",
    "            output.flush()\n",
    "            save = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'period': period,\n",
    "                'frames':frames,\n",
    "                'best_loss': bestLoss,\n",
    "                'loss': total / n,\n",
    "                'opt_dict': optim.state_dict()\n",
    "                }\n",
    "            torch.save(save, os.path.join(outputpath, \"verbose_normalizedsmallindex_checkpoint2.pt\"))\n",
    "            if total / n < bestLoss and phase == \"val\":\n",
    "                torch.save(save, os.path.join(outputpath, \"verbose_normalizedsmallindex_best2.pt\"))\n",
    "                bestLoss = total / n\n",
    "                print(\"This is the best yet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIRST RUN #### HERE are the numbers for the first 14 epochs in first run\n",
    "\n",
    "\n",
    "cuda is available\n",
    "  0%|                                                    | 1/932 [00:15<4:06:40, 15.90s/it, train1.0 55.1535 (55.1535)]C:\\Users\\Remote\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
    "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:36<00:00,  1.46it/s, train1.0 12.3963 (15.8264)]\n",
    "100%|██████████████████████████████████████████████████████| 161/161 [00:36<00:00,  4.36it/s, val1.0 11.3351 (14.4505)]\n",
    "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]\n",
    "This is the best yet\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:31<00:00,  1.48it/s, train2.0 11.1962 (10.4629)]\n",
    "100%|██████████████████████████████████████████████████████| 161/161 [00:36<00:00,  4.38it/s, val2.0 10.9464 (11.3590)]\n",
    "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]\n",
    "This is the best yet\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train3.0 11.1868 (15.0299)]\n",
    "100%|███████████████████████████████████████████████████████| 161/161 [00:36<00:00,  4.38it/s, val3.0 10.6582 (8.5865)]\n",
    "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]\n",
    "This is the best yet\n",
    "100%|█████████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train4.0 11.2358 (8.3774)]\n",
    "100%|██████████████████████████████████████████████████████| 161/161 [00:36<00:00,  4.38it/s, val4.0 10.6469 (15.1854)]\n",
    "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]\n",
    "This is the best yet\n",
    "100%|█████████████████████████████████████████████████████| 932/932 [10:31<00:00,  1.48it/s, train5.0 11.2808 (8.0343)]\n",
    "100%|███████████████████████████████████████████████████████| 161/161 [00:36<00:00,  4.36it/s, val5.0 10.7765 (9.4355)]\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train6.0 11.2152 (13.3924)]\n",
    "100%|██████████████████████████████████████████████████████| 161/161 [00:36<00:00,  4.40it/s, val6.0 10.8254 (14.5315)]\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train7.0 11.1704 (11.8043)]\n",
    "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.21it/s, val7.0 10.9360 (5.3713)]\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train8.0 11.2137 (11.0053)]\n",
    "100%|███████████████████████████████████████████████████████| 161/161 [00:37<00:00,  4.35it/s, val8.0 10.2768 (6.6230)]\n",
    "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]\n",
    "This is the best yet\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train9.0 11.3659 (10.9468)]\n",
    "100%|███████████████████████████████████████████████████████| 161/161 [00:37<00:00,  4.33it/s, val9.0 10.7838 (6.2929)]\n",
    "100%|███████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train10.0 11.3453 (11.4390)]\n",
    "100%|█████████████████████████████████████████████████████| 161/161 [00:37<00:00,  4.31it/s, val10.0 10.8094 (11.4828)]\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train11.0 11.1566 (9.6238)]\n",
    "100%|█████████████████████████████████████████████████████| 161/161 [00:37<00:00,  4.30it/s, val11.0 10.5223 (11.2068)]\n",
    "100%|████████████████████████████████████████████████████| 932/932 [10:32<00:00,  1.47it/s, train12.0 10.9960 (8.4571)]\n",
    "100%|██████████████████████████████████████████████████████| 161/161 [00:37<00:00,  4.32it/s, val12.0 11.0499 (8.3510)]\n",
    "100%|███████████████████████████████████████████████████| 932/932 [10:34<00:00,  1.47it/s, train13.0 11.2850 (11.6567)]\n",
    "100%|██████████████████████████████████████████████████████| 161/161 [01:38<00:00,  1.63it/s, val13.0 10.9843 (9.3447)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Remote\\Documents\\ishanjain\\echonet-function-evaluation\\Deep Learning\\output\\video\\r2plus1d_18_32_1_pretrained\\verbose_classification_normalizedsmallindex_checkpoint.pt False\n",
      "cuda is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 1/932 [00:13<3:25:18, 13.23s/it, train1.0 0.4486 (0.4486)]C:\\Users\\Remote\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:40<00:00,  1.46it/s, train1.0 0.4323 (0.4523)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.21it/s, val1.0 0.4318 (0.4349)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:41<00:00,  1.45it/s, train2.0 0.4314 (0.4308)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val2.0 0.4321 (0.4306)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train3.0 0.4312 (0.4284)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val3.0 0.4319 (0.4082)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train4.0 0.4308 (0.4271)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val4.0 0.4324 (0.4323)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train5.0 0.4306 (0.4280)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val5.0 0.4301 (0.4394)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train6.0 0.4308 (0.4214)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val6.0 0.4308 (0.4516)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train7.0 0.4307 (0.4272)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val7.0 0.4313 (0.4250)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train8.0 0.4305 (0.4226)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val8.0 0.4322 (0.4638)]\n",
      "100%|██████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train9.0 0.4307 (0.4343)]\n",
      "100%|████████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val9.0 0.4319 (0.4289)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train10.0 0.4305 (0.4185)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val10.0 0.4309 (0.4311)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train11.0 0.4304 (0.4353)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val11.0 0.4316 (0.4367)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train12.0 0.4308 (0.4431)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val12.0 0.4313 (0.4375)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train13.0 0.4308 (0.4219)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val13.0 0.4312 (0.4298)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train14.0 0.4305 (0.4347)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.13it/s, val14.0 0.4310 (0.4264)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train15.0 0.4303 (0.4385)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val15.0 0.4320 (0.4412)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:46<00:00,  1.44it/s, train16.0 0.4302 (0.4176)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val16.0 0.4310 (0.4324)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train17.0 0.4308 (0.4199)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.09it/s, val17.0 0.4307 (0.4217)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train18.0 0.4306 (0.4265)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val18.0 0.4303 (0.4203)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train19.0 0.4304 (0.4241)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.05it/s, val19.0 0.4307 (0.4308)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train20.0 0.4303 (0.4421)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val20.0 0.4315 (0.4215)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train21.0 0.4307 (0.4388)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val21.0 0.4304 (0.4274)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train22.0 0.4303 (0.4286)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val22.0 0.4310 (0.4232)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train23.0 0.4302 (0.4224)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val23.0 0.4304 (0.4370)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train24.0 0.4300 (0.4322)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val24.0 0.4301 (0.4301)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train25.0 0.4303 (0.4364)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val25.0 0.4304 (0.4162)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train26.0 0.4306 (0.4178)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val26.0 0.4306 (0.4349)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train27.0 0.4309 (0.4201)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val27.0 0.4308 (0.4220)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train28.0 0.4304 (0.4414)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val28.0 0.4313 (0.4352)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train29.0 0.4306 (0.4372)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.11it/s, val29.0 0.4313 (0.4306)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train30.0 0.4306 (0.4381)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val30.0 0.4301 (0.4335)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train31.0 0.4300 (0.4369)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val31.0 0.4301 (0.4275)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train32.0 0.4298 (0.4235)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.07it/s, val32.0 0.4303 (0.4311)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.44it/s, train33.0 0.4302 (0.4308)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val33.0 0.4311 (0.4218)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train34.0 0.4306 (0.4270)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val34.0 0.4312 (0.4369)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train35.0 0.4302 (0.4318)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val35.0 0.4306 (0.4357)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:45<00:00,  1.44it/s, train36.0 0.4297 (0.4287)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.15it/s, val36.0 0.4312 (0.4346)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train37.0 0.4298 (0.4350)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.14it/s, val37.0 0.4309 (0.4276)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train38.0 0.4301 (0.4155)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val38.0 0.4297 (0.4380)]\n",
      "  0%|                                                                                          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train39.0 0.4304 (0.4302)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.08it/s, val39.0 0.4310 (0.4299)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train40.0 0.4302 (0.4387)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.16it/s, val40.0 0.4305 (0.4224)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:44<00:00,  1.45it/s, train41.0 0.4298 (0.4308)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.13it/s, val41.0 0.4310 (0.4308)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train42.0 0.4306 (0.4368)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.12it/s, val42.0 0.4311 (0.4266)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train43.0 0.4300 (0.4204)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:39<00:00,  4.10it/s, val43.0 0.4309 (0.4241)]\n",
      "100%|█████████████████████████████████████████████████████| 932/932 [10:43<00:00,  1.45it/s, train44.0 0.4300 (0.4351)]\n",
      "100%|███████████████████████████████████████████████████████| 161/161 [00:38<00:00,  4.16it/s, val44.0 0.4306 (0.4332)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is for small index\n",
    "# Classification task instead of regression task on frame number\n",
    "\n",
    "# Changed model, with num classes as number of frames, and changed into cross entropy task and one_hot encoding of classes\n",
    "\n",
    "\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False, num_classes = frames)\n",
    "#model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 45\n",
    "verbose = True\n",
    "\n",
    "startingEpoch = 0\n",
    "startingBestLoss = 100000\n",
    "priorCheckpoint =  os.path.join(outputpath, \"verbose_classification_normalizedsmallindex_checkpoint.pt\")\n",
    "print(priorCheckpoint, os.path.exists(priorCheckpoint))\n",
    "\n",
    "toGPU = torch.cuda.is_available()\n",
    "#toGPU = False\n",
    "if toGPU:\n",
    "    print(\"cuda is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "if os.path.exists(priorCheckpoint):   \n",
    "    if toGPU:\n",
    "        print(\"loading weights\")\n",
    "        checkpoint = torch.load(priorCheckpoint)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "    else:\n",
    "        print(\"cuda is not available, cpu weights\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        checkpoint = torch.load(priorCheckpoint, map_location = \"cpu\")\n",
    "        state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "        model.load_state_dict(state_dict_cpu)\n",
    "        startingEpoch = checkpoint['epoch']\n",
    "        startingBestLoss = checkpoint['best_loss']\n",
    "learning_rate = 1e-4\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "bestLoss = startingBestLoss\n",
    "priorLines = None\n",
    "logFilename = os.path.join(outputpath, \"scripts\", \"verbose_classification_normalizedsmallindex.csv\")\n",
    "if os.path.exists(logFilename):\n",
    "    with open(logFilename, 'r') as output:\n",
    "        priorLines = output.readlines()\n",
    "else:\n",
    "    if not os.path.exists( os.path.join(outputpath, \"scripts\")):\n",
    "        os.mkdir(os.path.join(outputpath, \"scripts\"))\n",
    "# with open(logFilename, 'w') as output:\n",
    "#     for line in priorLines:\n",
    "#         output.write(line)\n",
    "with open(logFilename, 'w') as output:\n",
    "    for epoch in range(startingEpoch + 1, num_epochs):\n",
    "        if priorLines is not None:\n",
    "            for line in priorLines:\n",
    "                output.write(line)\n",
    "                print(line)\n",
    "        for phase in dataloaders.keys():\n",
    "            total = 0\n",
    "            n = 0\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                    for i, (x, outcome) in enumerate(dataloaders[phase]):\n",
    "                        \n",
    "    \n",
    "#                         if verbose:\n",
    "#                             print(i, outcome, outcome.type(torch.int64))\n",
    "                        \n",
    "#                         #one hot encoding of outcome, also needs to be int instead of double to use one_hot\n",
    "                        \n",
    "#                         one_hot = torch.nn.functional.one_hot(outcome.type(torch.int64), num_classes = frames)\n",
    "\n",
    "#                         if verbose:\n",
    "#                             print(i, x.shape, outcome.shape, one_hot.shape)\n",
    "                        \n",
    "                        x = x.to(device)\n",
    "                        outcome = outcome.to(device)\n",
    "                        #one_hot = one_hot.to(device)\n",
    "                        p = model(x)#[\"out\"]\n",
    "#                         if verbose:\n",
    "#                             print( x.shape, p.shape, outcome.shape)\n",
    "                        \n",
    "    \n",
    "                        loss = torch.nn.functional.cross_entropy(p, outcome.type(torch.int64)) #one_hot)\n",
    "                        \n",
    "                        total += loss.item()\n",
    "                        n += x.shape[0]\n",
    "                        progressbar.set_postfix_str(phase +\"{:.1f} {:.4f} ({:.4f})\".format(epoch, total / n, loss.item() /  x.shape[0]))\n",
    "                        progressbar.update()\n",
    "                        if(phase == 'train'):\n",
    "                            optim.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optim.step()\n",
    "            output.write(phase + \",\" + str(epoch) + \",\" + str(total/n) + \"\\n\")\n",
    "            output.flush()\n",
    "            save = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'period': period,\n",
    "                'frames':frames,\n",
    "                'best_loss': bestLoss,\n",
    "                'loss': total / n,\n",
    "                'opt_dict': optim.state_dict()\n",
    "                }\n",
    "            torch.save(save, os.path.join(outputpath, \"verbose_classification_normalizedsmallindex_checkpoint2.pt\"))\n",
    "            if total / n < bestLoss and phase == \"val\":\n",
    "                torch.save(save, os.path.join(outputpath, \"verbose_classification_normalizedsmallindex_best2.pt\"))\n",
    "                bestLoss = total / n\n",
    "                print(\"This is the best yet\")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10]) torch.Size([10, 32])\n"
     ]
    }
   ],
   "source": [
    "n_classes = 32\n",
    "n_samples = 10\n",
    "\n",
    "# Create list n_samples random labels (can also be numpy array)\n",
    "labels = [random.randrange(n_classes) for _ in range(n_samples)]\n",
    "# Convert to torch Tensor\n",
    "labels_tensor = torch.as_tensor(labels)\n",
    "\n",
    "\n",
    "# Create one-hot encodings of labels\n",
    "one_hot = torch.nn.functional.one_hot(labels_tensor, num_classes=n_classes)\n",
    "print(labels_tensor.shape, one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21.,  4., 24.,  8., 27.,  1., 17.,  7.]) tensor([21,  4, 24,  8, 27,  1, 17,  7], dtype=torch.int8) tensor([26, 13, 14,  0, 11, 17,  9, 30, 13, 12])\n"
     ]
    }
   ],
   "source": [
    "print(outcome, outcome.type(torch.int8), labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6e847d8fb042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "one_hot = torch.nn.functional.one_hot(labels_tensor, num_classes=n_classes)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "one_hot = torch.nn.functional.one_hot(outcome.type(torch.int64), num_classes=n_classes)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrainedloss testing\n",
    "# search just training on CE\n",
    "\n",
    "#bestRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_SQLguide_True_AugmentTrue_best.pt\"\n",
    "bestLVweights = \"C:\\\\Users\\\\Windows\\\\Dropbox\\\\Echo Research\\\\CodeBase\\\\EchoNetDynamic-Weights\\\\deeplabv3_resnet50_random.pt\"\n",
    "\n",
    "numWork = 10\n",
    "numberOfSubsequentFrames = 5\n",
    "bs = 45\n",
    "numEpochs = 50\n",
    "\n",
    "for weightOfConstraint in [0]: #[0.8, 0.85, 0.9, 0.95]: #  0.5, 0.1, 0, 0.9, 1 ]: #1, 0,  0.9, #   1000, 100,  10, 1]:\n",
    "    for CrossEntropyLoss in [1]:\n",
    "        for SonoData in [False]:\n",
    "            for doAugmentation in [False]:\n",
    "                for doPretrain in [True]:\n",
    "\n",
    "\n",
    "                    train_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"train\", fuzzyAugmentation=doAugmentation,constrainSubsequent=numberOfSubsequentFrames,useSonoData=False)\n",
    "\n",
    "                    if SonoData:\n",
    "                        sono_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"train\", fuzzyAugmentation=doAugmentation,constrainSubsequent=numberOfSubsequentFrames,useSonoData=True)\n",
    "                        train_dataloader = torch.utils.data.DataLoader(torch.utils.data.ConcatDataset([train_dataset,sono_dataset]), batch_size = bs, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "                    else:\n",
    "                        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = bs, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "                    val_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"val\", fuzzyAugmentation=False,constrainSubsequent=numberOfSubsequentFrames,useSonoData=False)\n",
    "                    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = bs, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "                    dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "\n",
    "                    device = torch.device(\"cuda\")\n",
    "\n",
    "                    model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained = False, aux_loss = False)\n",
    "                    model.classifier[-1] = torch.nn.Conv2d(model.classifier[-1].in_channels, 1, kernel_size = model.classifier[-1].kernel_size)\n",
    "\n",
    "                    if device.type == \"cuda\":\n",
    "                        model = torch.nn.DataParallel(model)\n",
    "                    model.to(device)\n",
    "\n",
    "                    if doPretrain:\n",
    "                        print(\"load from weights\")\n",
    "                        checkpoint = torch.load(bestLVweights)#LVWeights) #currentRVweights)#\n",
    "                        model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "                    #optim = torch.optim.SGD(model.parameters(), lr=1000, momentum=0.9)\n",
    "                    learning_rate = 1e-2\n",
    "                    optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                    #optim = torch.optim.Adagrad(model.parameters(), lr=100)\n",
    "\n",
    "                    bestLoss = 1000000\n",
    "\n",
    "                    with open(\"LossAcrossEpochs_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_withCrossEntropyOnly\"+ str(CrossEntropyLoss) + \"_withL2ConstrainedLoss\"+ str(weightOfConstraint) + \"_\"+str(numEpochs)+\"_Adam.csv\", 'w') as output:\n",
    "                        for epoch in range(numEpochs):\n",
    "                            for phase in dataloaders.keys():\n",
    "\n",
    "                                total = 0\n",
    "                                n = 0\n",
    "                                dsctotal = 0\n",
    "                                cetotal = 0\n",
    "                                constrainedTotal = 0\n",
    "\n",
    "                                with torch.set_grad_enabled(phase != 'val'):\n",
    "                                    with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                                        for (i, (x,y)) in enumerate(dataloaders[phase]):\n",
    "\n",
    "                                            x = x.to(device)\n",
    "                                            y = y.to(device)\n",
    "                                            #print(y.min(), y.max())\n",
    "                                            #print(x.shape)\n",
    "\n",
    "                                            #print(\"input shape\", x.shape)\n",
    "\n",
    "                                            # reshape to be bs x frames indepedent predictions on (3,112,112) images\n",
    "                                            x = torch.transpose(x, 1, 4)\n",
    "                                            #print(x.shape)\n",
    "                                            x = x.reshape(bs * numberOfSubsequentFrames,  112, 112, 3).transpose(1,2)\n",
    "                                            x = torch.transpose(x, 1, 3).type(torch.float)\n",
    "\n",
    "                                            #print(\"new input shape\", x.shape)\n",
    "\n",
    "                                            p = model(x)[\"out\"]\n",
    "\n",
    "                                            #print(\"predictions shape\", p.shape)\n",
    "\n",
    "                                            constrainedLoss = variousLossFunctions.constrainSubsequentLoss(p, bs, numberOfSubsequentFrames)\n",
    "                                            dscloss = x.shape[0] / numberOfSubsequentFrames - variousLossFunctions.diceLoss(p[0::numberOfSubsequentFrames, 0, :, :], y,)\n",
    "                                            celoss = torch.nn.functional.binary_cross_entropy_with_logits(p[0::numberOfSubsequentFrames, 0, :, :], y, reduction = \"sum\") / 112 / 112\n",
    "\n",
    "                                            loss =  (1-weightOfConstraint) * celoss + weightOfConstraint * constrainedLoss\n",
    "                                            #CrossEntropyLoss * torch.nn.functional.binary_cross_entropy_with_logits(p[0::numberOfSubsquentFrames, 0, :, :], y, reduction = \"sum\") / 112 / 112 + variousLossFunctions.constrainSubsequentLoss(p, bs, numberOfSubsequentFrames).item()#x.shape[0] - variousLossFunctions.diceLoss(p[:, 0, :, :], y,) +\n",
    "                                            \n",
    "#                                            loss = loss.item()\n",
    "                                            total += loss#.item()\n",
    "                                            dsctotal += dscloss#.item()\n",
    "                                            cetotal += celoss#.item()\n",
    "                                            constrainedTotal += constrainedLoss\n",
    "\n",
    "                                            n += x.shape[0] / numberOfSubsequentFrames\n",
    "\n",
    "                                            #print(loss, total, n, flush = True)\n",
    "\n",
    "                                            progressbar.set_postfix_str(phase + \"{:.1f} total{:.4f} dsc{:.4f} ce{:.4f} constrain{:.4f}  ({:.4f})\".format( epoch, total / n , dsctotal / n , cetotal / n , constrainedTotal / n, loss / x.size(0) * numberOfSubsequentFrames )) #/ 112 / 112\n",
    "                                            progressbar.update()\n",
    "\n",
    "                                            if(phase != 'val'):\n",
    "                                                optim.zero_grad()\n",
    "                                                loss.backward()\n",
    "                                                optim.step()\n",
    "\n",
    "                                        output.write(phase + \",\" + str(epoch) + \",\" + str(total.item() / n ) + \",\" + str(dsctotal.item() / n ) + \",\" + str(cetotal.item() / n ) + ',' + str(constrainedTotal.item() / n) + \"\\n\") #/ 112 / 112\n",
    "\n",
    "                                        if phase == 'val':\n",
    "                                            currentRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_crossEntropyOnly\"+ str(CrossEntropyLoss) + \"_withL2ConstrainedLoss\"+ str(weightOfConstraint)  + \"_\"+str(numEpochs)+\"_Adam_current.pt\"\n",
    "                                            torch.save(model.state_dict(), currentRVweights)\n",
    "\n",
    "                                            if (total / n ) < bestLoss: #/ 112 / 112)\n",
    "                                                bestLoss = (total / n ) # / 112 / 112)\n",
    "                                                print(\"this is the best so far\", str(bestLoss), flush = True)\n",
    "                                                bestRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_crossEntropyOnly\"+ str(CrossEntropyLoss) +\"_withL2ConstrainedLoss\"+ str(weightOfConstraint)  + \"_\"+str(numEpochs)+\"_Adam_best.pt\"\n",
    "                                                torch.save(model.state_dict(), bestRVweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrainedloss testing with smaller loss, same sweep region\n",
    "\n",
    "#bestRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_SQLguide_True_AugmentTrue_best.pt\"\n",
    "bestLVweights = \"C:\\\\Users\\\\Windows\\\\Dropbox\\\\Echo Research\\\\CodeBase\\\\EchoNetDynamic-Weights\\\\deeplabv3_resnet50_random.pt\"\n",
    "\n",
    "numWork = 10\n",
    "numberOfSubsequentFrames = 5\n",
    "bs = 45\n",
    "numEpochs = 100\n",
    "\n",
    "for weightOfConstraint in  [0.8, 0.85, 0.9, 0.95]: #[0, 0.25, 0.1, 0.5, 0.75, 0.9, 1]: #  0.5, 0.1, 0, 0.9, 1 ]: #1, 0,  0.9, #   1000, 100,  10, 1]:\n",
    "    for CrossEntropyLoss in [1]:\n",
    "        for SonoData in [False]:\n",
    "            for doAugmentation in [False]:\n",
    "                for doPretrain in [False]:\n",
    "\n",
    "\n",
    "                    train_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"train\", fuzzyAugmentation=doAugmentation,constrainSubsequent=numberOfSubsequentFrames,useSonoData=False)\n",
    "\n",
    "                    if SonoData:\n",
    "                        sono_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"train\", fuzzyAugmentation=doAugmentation,constrainSubsequent=numberOfSubsequentFrames,useSonoData=True)\n",
    "                        train_dataloader = torch.utils.data.DataLoader(torch.utils.data.ConcatDataset([train_dataset,sono_dataset]), batch_size = bs, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "                    else:\n",
    "                        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = bs, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "                    val_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"val\", fuzzyAugmentation=False,constrainSubsequent=numberOfSubsequentFrames,useSonoData=False)\n",
    "                    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = bs, num_workers = numWork, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "                    dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "\n",
    "                    device = torch.device(\"cuda\")\n",
    "\n",
    "                    model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained = False, aux_loss = False)\n",
    "                    model.classifier[-1] = torch.nn.Conv2d(model.classifier[-1].in_channels, 1, kernel_size = model.classifier[-1].kernel_size)\n",
    "\n",
    "                    if device.type == \"cuda\":\n",
    "                        model = torch.nn.DataParallel(model)\n",
    "                    model.to(device)\n",
    "\n",
    "                    if doPretrain:\n",
    "                        print(\"load from weights\")\n",
    "                        checkpoint = torch.load(bestLVweights)#LVWeights) #currentRVweights)#\n",
    "                        model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "                    #optim = torch.optim.SGD(model.parameters(), lr=1000, momentum=0.9)\n",
    "                    learning_rate = 1e-2\n",
    "                    optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                    #optim = torch.optim.Adagrad(model.parameters(), lr=100)\n",
    "\n",
    "                    bestLoss = 1000000\n",
    "\n",
    "                    with open(\"LossAcrossEpochs_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_withCrossEntropyOnly\"+ str(CrossEntropyLoss) + \"_withL2ConstrainedLoss\"+ str(weightOfConstraint) + \"_\"+str(numEpochs)+\"_Adam.csv\", 'w') as output:\n",
    "                        for epoch in range(numEpochs):\n",
    "                            for phase in dataloaders.keys():\n",
    "\n",
    "                                total = 0\n",
    "                                n = 0\n",
    "                                dsctotal = 0\n",
    "                                cetotal = 0\n",
    "                                constrainedTotal = 0\n",
    "\n",
    "                                with torch.set_grad_enabled(phase != 'val'):\n",
    "                                    with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                                        for (i, (x,y)) in enumerate(dataloaders[phase]):\n",
    "\n",
    "                                            x = x.to(device)\n",
    "                                            y = y.to(device)\n",
    "                                            #print(y.min(), y.max())\n",
    "                                            #print(x.shape)\n",
    "\n",
    "                                            #print(\"input shape\", x.shape)\n",
    "\n",
    "                                            # reshape to be bs x frames indepedent predictions on (3,112,112) images\n",
    "                                            x = torch.transpose(x, 1, 4)\n",
    "                                            #print(x.shape)\n",
    "                                            x = x.reshape(bs * numberOfSubsequentFrames,  112, 112, 3).transpose(1,2)\n",
    "                                            x = torch.transpose(x, 1, 3).type(torch.float)\n",
    "\n",
    "                                            #print(\"new input shape\", x.shape)\n",
    "\n",
    "                                            p = model(x)[\"out\"]\n",
    "\n",
    "                                            #print(\"predictions shape\", p.shape)\n",
    "\n",
    "                                            constrainedLoss = variousLossFunctions.constrainSubsequentLoss(p, bs, numberOfSubsequentFrames) / 112 / 112\n",
    "                                            dscloss = x.shape[0] / numberOfSubsequentFrames - variousLossFunctions.diceLoss(p[0::numberOfSubsequentFrames, 0, :, :], y,)\n",
    "                                            celoss = torch.nn.functional.binary_cross_entropy_with_logits(p[0::numberOfSubsequentFrames, 0, :, :], y, reduction = \"sum\") / 112 / 112\n",
    "\n",
    "                                            loss =  (1-weightOfConstraint) * celoss + weightOfConstraint * constrainedLoss\n",
    "                                            #CrossEntropyLoss * torch.nn.functional.binary_cross_entropy_with_logits(p[0::numberOfSubsquentFrames, 0, :, :], y, reduction = \"sum\") / 112 / 112 + variousLossFunctions.constrainSubsequentLoss(p, bs, numberOfSubsequentFrames).item()#x.shape[0] - variousLossFunctions.diceLoss(p[:, 0, :, :], y,) +\n",
    "                                            \n",
    "#                                            loss = loss.item()\n",
    "                                            total += loss#.item()\n",
    "                                            dsctotal += dscloss#.item()\n",
    "                                            cetotal += celoss#.item()\n",
    "                                            constrainedTotal += constrainedLoss\n",
    "\n",
    "                                            n += x.shape[0] / numberOfSubsequentFrames\n",
    "\n",
    "                                            #print(loss, total, n, flush = True)\n",
    "\n",
    "                                            progressbar.set_postfix_str(phase + \"{:.1f} total{:.4f} dsc{:.4f} ce{:.4f} constrain{:.4f}  ({:.4f})\".format( epoch, total / n , dsctotal / n , cetotal / n , constrainedTotal / n, loss / x.size(0) * numberOfSubsequentFrames )) #/ 112 / 112\n",
    "                                            progressbar.update()\n",
    "\n",
    "                                            if(phase != 'val'):\n",
    "                                                optim.zero_grad()\n",
    "                                                loss.backward()\n",
    "                                                optim.step()\n",
    "\n",
    "                                        output.write(phase + \",\" + str(epoch) + \",\" + str(total.item() / n ) + \",\" + str(dsctotal.item() / n ) + \",\" + str(cetotal.item() / n ) + ',' + str(constrainedTotal.item() / n) + \"\\n\") #/ 112 / 112\n",
    "\n",
    "                                        if phase == 'val':\n",
    "                                            currentRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_crossEntropyOnly\"+ str(CrossEntropyLoss) + \"_withL2ConstrainedLoss\"+ str(weightOfConstraint)  + \"_\"+str(numEpochs)+\"_Adam_current.pt\"\n",
    "                                            torch.save(model.state_dict(), currentRVweights)\n",
    "\n",
    "                                            if (total / n ) < bestLoss: #/ 112 / 112)\n",
    "                                                bestLoss = (total / n ) # / 112 / 112)\n",
    "                                                print(\"this is the best so far\", str(bestLoss), flush = True)\n",
    "                                                bestRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_crossEntropyOnly\"+ str(CrossEntropyLoss) +\"_withL2ConstrainedLoss\"+ str(weightOfConstraint)  + \"_\"+str(numEpochs)+\"_Adam_best.pt\"\n",
    "                                                torch.save(model.state_dict(), bestRVweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter search without constrained loss\n",
    "\n",
    "#bestRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_SQLguide_True_AugmentTrue_best.pt\"\n",
    "bestLVweights = \"C:\\\\Users\\\\Windows\\\\Dropbox\\\\Echo Research\\\\CodeBase\\\\EchoNetDynamic-Weights\\\\deeplabv3_resnet50_random.pt\"\n",
    "\n",
    "for diceLoss in [0,1]:\n",
    "    for CrossEntropyLoss in [0,1]:\n",
    "        for SonoData in [ False, True]:\n",
    "            for doAugmentation in [False, True]:\n",
    "                for doPretrain in [True]:\n",
    "                    if(diceLoss + CrossEntropyLoss > 0):\n",
    "                        print(diceLoss, CrossEntropyLoss, SonoData, doAugmentation, doPretrain)\n",
    "                        \n",
    "                        train_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"train\", fuzzyAugmentation=doAugmentation,constrainSubsequent=0,useSonoData=False)\n",
    "\n",
    "                        if SonoData:\n",
    "                            sono_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"train\", fuzzyAugmentation=doAugmentation,constrainSubsequent=0,useSonoData=True)\n",
    "                            train_dataloader = torch.utils.data.DataLoader(torch.utils.data.ConcatDataset([train_dataset,sono_dataset]), batch_size = 100, num_workers = 5, shuffle = True, pin_memory = True, drop_last = True)\n",
    "                        else:\n",
    "                            train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 100, num_workers = 5, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "                        val_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"val\", fuzzyAugmentation=False,constrainSubsequent=0,useSonoData=False)\n",
    "                        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = 100, num_workers = 5, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "                        dataloaders = {'train':train_dataloader, 'val':val_dataloader}\n",
    "\n",
    "                        device = torch.device(\"cuda\")\n",
    "\n",
    "                        model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained = False, aux_loss = False)\n",
    "                        model.classifier[-1] = torch.nn.Conv2d(model.classifier[-1].in_channels, 1, kernel_size = model.classifier[-1].kernel_size)\n",
    "\n",
    "                        if device.type == \"cuda\":\n",
    "                            model = torch.nn.DataParallel(model)\n",
    "                        model.to(device)\n",
    "\n",
    "                        if doPretrain:\n",
    "                            print(\"load from weights\")\n",
    "                            checkpoint = torch.load(bestLVweights)#LVWeights) #currentRVweights)#\n",
    "                            model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "                        learning_rate = 1e-4\n",
    "                        optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                        # optim = torch.optim.Adagrad(model.parameters(), lr=100)\n",
    "\n",
    "                        bestLoss = 1000000\n",
    "\n",
    "                        with open(\"LossAcrossEpochs_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_diceLoss\"+ str(diceLoss) + \"_CrossEntropyLoss\"+ str(CrossEntropyLoss) + \"_Adam.csv\", 'w') as output:\n",
    "                            for epoch in range(50):\n",
    "                                for phase in dataloaders.keys():\n",
    "\n",
    "                                    total = 0\n",
    "                                    n = 0\n",
    "                                    dsctotal = 0\n",
    "                                    cetotal = 0\n",
    "\n",
    "                                    with torch.set_grad_enabled(phase != 'val'):\n",
    "                                        with tqdm.tqdm(total = len(dataloaders[phase])) as progressbar:\n",
    "                                            for (i, (x,y)) in enumerate(dataloaders[phase]):\n",
    "\n",
    "                                                x = x.to(device)\n",
    "                                                y = y.to(device)\n",
    "                                                #print(y.min(), y.max())\n",
    "                                                #print(x.shape)\n",
    "                                                p = model(x)[\"out\"]\n",
    "                                                loss = diceLoss * (x.shape[0] - variousLossFunctions.diceLoss(p[:, 0, :, :], y,)) + CrossEntropyLoss * torch.nn.functional.binary_cross_entropy_with_logits(p[:, 0, :, :], y, reduction = \"sum\") / 112 / 112 #+ variousLossFunctions.diceLoss(p[:, 0, :, :], y,)\n",
    "                                                dscloss = x.shape[0] - variousLossFunctions.diceLoss(p[:, 0, :, :], y,)\n",
    "                                                celoss = torch.nn.functional.binary_cross_entropy_with_logits(p[:, 0, :, :], y, reduction = \"sum\") / 112 / 112\n",
    "\n",
    "                                                total += loss.item()\n",
    "                                                dsctotal += dscloss#.item()\n",
    "                                                cetotal += celoss#.item()\n",
    "\n",
    "                                                n += x.shape[0]\n",
    "\n",
    "                                                #print(loss, total, n, flush = True)\n",
    "\n",
    "                                                progressbar.set_postfix_str(phase + \"{:.1f} {:.4f} {:.4f} {:.4f}  ({:.4f})\".format( epoch, total / n , dsctotal / n , cetotal / n , loss.item() / x.size(0) )) #/ 112 / 112\n",
    "                                                progressbar.update()\n",
    "\n",
    "                                                if(phase != 'val'):\n",
    "                                                    optim.zero_grad()\n",
    "                                                    loss.backward()\n",
    "                                                    optim.step()\n",
    "\n",
    "                                            output.write(phase + \",\" + str(epoch) + \",\" + str(total / n ) + \",\" + str(dsctotal.item() / n ) + \",\" + str(cetotal.item() / n ) + \"\\n\") #/ 112 / 112\n",
    "\n",
    "                                            if phase == 'val':\n",
    "                                                currentRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_diceLoss\"+ str(diceLoss) + \"_CrossEntropyLoss\"+ str(CrossEntropyLoss) + \"_Adam_current.pt\"\n",
    "                                                torch.save(model.state_dict(), currentRVweights)\n",
    "\n",
    "                                                if (total / n ) < bestLoss: #/ 112 / 112)\n",
    "                                                    bestLoss = (total / n ) # / 112 / 112)\n",
    "                                                    print(\"this is the best so far\", str(bestLoss), flush = True)\n",
    "                                                    bestRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_Pretrain\"+str(doPretrain)+\"_Sono\"+str(SonoData)+\"_Augment\"+str(doAugmentation)+ \"_diceLoss\"+ str(diceLoss) + \"_CrossEntropyLoss\"+ str(CrossEntropyLoss) +\"_Adam_best.pt\"\n",
    "                                                    torch.save(model.state_dict(), bestRVweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    x, f = zip(*x)\n",
    "    i = list(map(lambda t: t.shape[1], x))\n",
    "    x = torch.as_tensor(np.swapaxes(np.concatenate(x, 1), 0, 1))\n",
    "    return x, f, i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate videos from both test set of RV focused Views\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "testFolder = \"C:\\\\Users\\\\Windows\\\\Dropbox\\\\Echo Research\\\\CodeBase\\\\DynamicRV\\\\Constrained\\\\SmallTestSet\"\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(echonet.datasets.Echo(split=\"external_test\", external_test_location = testFolder, target_type=[\"Filename\"], length=None, period=1, mean=mean, std=std),\n",
    "                                        batch_size=100, num_workers=0, shuffle=False, pin_memory=(device.type == \"cuda\"), collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# test_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"test\", fuzzyAugmentation=False,constrainSubsequent=0,useSonoData=False)\n",
    "# dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, num_workers = 0, shuffle = False, pin_memory=(device.type == \"cuda\"), collate_fn=collate_fn)\n",
    "          \n",
    "stem = \"C:\\\\Datasets\\\\RVWork\\\\RV_deeplab_50_PretrainFalse_SonoFalse_AugmentFalse_crossEntropyOnly1_with\"\n",
    "# foldername = [\"FullFeatures_DiceLoss_RVViews\",\"FullFeatures_CELoss_RVViews\",\"FullFeatures_BothLoss_RVViews\"]\n",
    "loss = [\"L2\", \"L1\"]\n",
    "weight = [\"1\", \"0.9\", \"0.75\", \"0.5\", \"0.25\", \"0.1\", \"0\"]\n",
    "folder = \"Constrained\\\\ExamplesWithBiggerLoss\"\n",
    "bestRVweights = [\"ConstrainedLoss1_50_Adam_best.pt\",\n",
    "                \"ConstrainedLoss0.9_50_Adam_best.pt\",\n",
    "                 \"ConstrainedLoss0.75_50_Adam_best.pt\",\n",
    "                 \"ConstrainedLoss0.5_50_Adam_best.pt\",\n",
    "                 \"ConstrainedLoss0.25_50_Adam_best.pt\",\n",
    "                 \"ConstrainedLoss0.1_50_Adam_best.pt\",\n",
    "                 \"ConstrainedLoss0_50_Adam_best.pt\"]\n",
    "\n",
    "\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained = False, aux_loss = False)\n",
    "model.classifier[-1] = torch.nn.Conv2d(model.classifier[-1].in_channels, 1, kernel_size = model.classifier[-1].kernel_size)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "     model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "for thisLoss in loss:\n",
    "    for count, thisweight in enumerate(bestRVweights):\n",
    "        print(count, thisLoss, thisweight)\n",
    "        checkpoint = torch.load(stem + thisLoss + thisweight)\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "\n",
    "        #all_dataset = dataset.Dataset(SQLtracings, SQLvideos, mean, std, split=\"all\", fuzzyAugmentation=False,constrainSubsequent=0)\n",
    "        #dataloader = torch.utils.data.DataLoader(all_dataset, batch_size = 200, num_workers = 10, shuffle = True, pin_memory = True, drop_last = True)\n",
    "\n",
    "        #bestRVweights = \"C:\\\\Datasets\\RVWork\\\\RV_deeplab_50_Sono_True_Pretrain_False_Augment_False_best.pt\"\n",
    "        #\n",
    "        #checkpoint = torch.load(bestRVweights)\n",
    "        #model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "        #os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        block = 256\n",
    "        with torch.no_grad():\n",
    "            for (x, f, i) in tqdm.tqdm(dataloader):\n",
    "                x = x.to(device)\n",
    "                y = np.concatenate([model(x[i:(i + block), :, :, :])[\"out\"].detach().cpu().numpy() for i in range(0, x.shape[0], block)]).astype(np.float16)\n",
    "\n",
    "                start = 0\n",
    "                x = (x.cpu().numpy() * std.reshape((1, 3, 1, 1))) + mean.reshape((1, 3, 1, 1))\n",
    "\n",
    "                for (filename, offset) in zip(f, i):\n",
    "                    img = x[start:(start + offset), ...].transpose((1, 0, 2, 3))\n",
    "                    img = np.concatenate((img, img), 3)\n",
    "                    logit = y[start:(start + offset), 0, :, :].copy()\n",
    "                    img[1, :, :, 112:] = np.maximum(255. * (logit > 0), img[0, :, :, 112:])\n",
    "\n",
    "                    #img = y[start:(start + offset)]\n",
    "                    #np.save(os.path.join(output, \"labels\", os.path.splitext(filename)[0]), y[start:(start + offset), 0, :, :])\n",
    "                    echonet.utils.savevideo(os.path.join(folder, os.path.splitext(filename)[0] + \"_\" + thisLoss + \"_\"+ weight[count] + \".avi\"), img.astype(np.uint8), 50)\n",
    "\n",
    "                    start += offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
